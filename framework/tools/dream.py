#!/usr/bin/env python3
"""
dream.py ‚Äî BMAD Dream Mode : consolidation hors-session et insights √©mergents.
==============================================================================

Simule une phase de "r√™ve" : les agents relisent learnings, decisions, trace,
failure museum et shared-context, puis produisent des insights cross-domaine
qu'aucun agent n'aurait formul√©s en session.

Mode read-only : aucun fichier n'est modifi√©. Les insights sont √©crits dans
_bmad-output/dream-journal.md pour review humain.

Usage :
  python3 dream.py --project-root .                   # Dream complet
  python3 dream.py --project-root . --since 2026-01-01 # Depuis une date
  python3 dream.py --project-root . --agent dev        # Focus un agent
  python3 dream.py --project-root . --validate         # Valider les insights (no hallucination)
  python3 dream.py --project-root . --dry-run          # Preview sans √©crire

Stdlib only ‚Äî aucune d√©pendance externe.
"""

import argparse
import json
import re
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path

# ‚îÄ‚îÄ Constantes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

MAX_INSIGHTS = 12          # Plafond d'insights par dream
MIN_SOURCES = 2            # Un insight doit croiser ‚â• 2 sources
SIMILARITY_THRESHOLD = 0.6 # Seuil de d√©tection doublon
STALENESS_DAYS = 7         # Insight plus ancien = moindre poids
QUICK_MAX_INSIGHTS = 5     # Plafond en mode quick (O(n) seulement)
PERSISTENCE_BOOST = 0.15   # Bonus confiance pour insight persistant
DECAY_HALFLIFE_DAYS = 14   # Demi-vie pour la pond√©ration temporelle
DREAM_MEMORY_FILE = "dream-memory.json"  # Historique structur√© des insights


# ‚îÄ‚îÄ Data classes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@dataclass
class DreamSource:
    """Une source de donn√©es pour le dream."""
    name: str          # ex. "learnings/dev.md"
    kind: str          # learnings | decisions | trace | failure-museum | shared-context
    entries: list[str] = field(default_factory=list)
    dates: list[str] = field(default_factory=list)


@dataclass
class DreamInsight:
    """Un insight √©mergent produit par le dream."""
    title: str
    description: str
    sources: list[str]        # noms des fichiers sources
    category: str             # pattern | tension | opportunity | connection
    confidence: float         # 0.0 - 1.0
    agents_relevant: list[str] = field(default_factory=list)
    actionable: bool = False


# ‚îÄ‚îÄ Collecte des sources ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def collect_sources(project_root: Path, since: str | None = None,
                    agent_filter: str | None = None) -> list[DreamSource]:
    """Collecte toutes les sources de m√©moire du projet."""
    sources: list[DreamSource] = []
    memory_dir = project_root / "_bmad" / "_memory"

    # 1. Learnings
    learnings_dir = memory_dir / "agent-learnings"
    if learnings_dir.exists():
        for f in sorted(learnings_dir.glob("*.md")):
            if agent_filter and agent_filter.lower() not in f.stem.lower():
                continue
            entries = _parse_markdown_entries(f, since)
            if entries:
                sources.append(DreamSource(
                    name=f"learnings/{f.name}",
                    kind="learnings",
                    entries=[e[1] for e in entries],
                    dates=[e[0] for e in entries],
                ))

    # 2. Decisions log
    decisions_file = memory_dir / "decisions-log.md"
    if decisions_file.exists():
        entries = _parse_markdown_entries(decisions_file, since)
        if entries:
            sources.append(DreamSource(
                name="decisions-log.md",
                kind="decisions",
                entries=[e[1] for e in entries],
                dates=[e[0] for e in entries],
            ))

    # 3. BMAD_TRACE
    trace_file = project_root / "_bmad-output" / "BMAD_TRACE.md"
    if trace_file.exists():
        entries = _parse_trace_entries(trace_file, since, agent_filter)
        if entries:
            sources.append(DreamSource(
                name="BMAD_TRACE.md",
                kind="trace",
                entries=[e[1] for e in entries],
                dates=[e[0] for e in entries],
            ))

    # 4. Failure Museum
    failure_file = memory_dir / "failure-museum.md"
    if failure_file.exists():
        entries = _parse_markdown_entries(failure_file, since)
        if entries:
            sources.append(DreamSource(
                name="failure-museum.md",
                kind="failure-museum",
                entries=[e[1] for e in entries],
                dates=[e[0] for e in entries],
            ))

    # 5. Shared context
    shared_file = memory_dir / "shared-context.md"
    if shared_file.exists():
        content = shared_file.read_text(encoding="utf-8")
        sections = _parse_shared_context_sections(content)
        if sections:
            sources.append(DreamSource(
                name="shared-context.md",
                kind="shared-context",
                entries=sections,
            ))

    # 6. Contradiction log
    contradiction_file = memory_dir / "contradiction-log.md"
    if contradiction_file.exists():
        entries = _parse_markdown_entries(contradiction_file, since)
        if entries:
            sources.append(DreamSource(
                name="contradiction-log.md",
                kind="contradictions",
                entries=[e[1] for e in entries],
                dates=[e[0] for e in entries],
            ))

    # 7. Pheromone board (feedback loop ‚Äî dream lit les signaux stigmergy)
    pheromone_entries = _parse_pheromone_board(project_root, since)
    if pheromone_entries:
        sources.append(DreamSource(
            name="pheromone-board.json",
            kind="stigmergy",
            entries=[e[1] for e in pheromone_entries],
            dates=[e[0] for e in pheromone_entries],
        ))

    return sources


def _parse_markdown_entries(path: Path, since: str | None = None) -> list[tuple[str, str]]:
    """Parse un fichier markdown et retourne [(date, text), ...]."""
    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return []

    entries: list[tuple[str, str]] = []
    date_pattern = re.compile(r'\[(\d{4}-\d{2}-\d{2})')

    for line in content.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        # Chercher une date dans la ligne
        match = date_pattern.search(line)
        entry_date = match.group(1) if match else ""
        if since and entry_date and entry_date < since:
            continue
        if line.startswith("- ") or line.startswith("* "):
            entries.append((entry_date, line[2:].strip()))

    return entries


def _parse_trace_entries(path: Path, since: str | None = None,
                         agent_filter: str | None = None) -> list[tuple[str, str]]:
    """Parse BMAD_TRACE.md pour les entr√©es pertinentes."""
    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return []

    entries: list[tuple[str, str]] = []
    trace_pattern = re.compile(
        r'\[(\d{4}-\d{2}-\d{2})[^\]]*\]\s*\[(\w+)\]\s*\[([^\]]+)\]\s*(.*)'
    )

    for line in content.splitlines():
        match = trace_pattern.match(line.strip())
        if not match:
            continue
        entry_date, level, agent, payload = match.groups()
        if since and entry_date < since:
            continue
        if agent_filter and agent_filter.lower() not in agent.lower():
            continue
        # Focus sur DECISION, CHECKPOINT, FAILURE
        if level in ("DECISION", "CHECKPOINT", "FAILURE", "REMEMBER"):
            entries.append((entry_date, f"[{agent}] [{level}] {payload}"))

    return entries


def _parse_shared_context_sections(content: str) -> list[str]:
    """Extrait les sections non-vides du shared-context."""
    sections: list[str] = []
    current = ""
    for line in content.splitlines():
        if line.startswith("## "):
            if current.strip():
                sections.append(current.strip())
            current = line + "\n"
        else:
            current += line + "\n"
    if current.strip():
        sections.append(current.strip())
    return sections


def _parse_pheromone_board(project_root: Path,
                          since: str | None = None) -> list[tuple[str, str]]:
    """Parse le pheromone-board.json comme source pour le dream.

    Retourne [(date, text), ...] pour chaque ph√©romone active non-r√©solue.
    Filtre les ph√©romones √©mises par dream-mode pour √©viter l'auto-r√©f√©rence,
    sauf celles qui ont √©t√© amplifi√©es (= feedback humain/agent).
    """
    board_path = project_root / "_bmad-output" / "pheromone-board.json"
    if not board_path.exists():
        return []
    try:
        data = json.loads(board_path.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return []

    entries: list[tuple[str, str]] = []
    for p in data.get("pheromones", []):
        if p.get("resolved", False):
            continue

        # Skip dream's own pheromones UNLESS they got reinforced (= feedback signal)
        if p.get("emitter") == "dream-mode" and p.get("reinforcements", 0) == 0:
            continue

        # Date filter
        ts = p.get("timestamp", "")
        entry_date = ts[:10] if len(ts) >= 10 else ""
        if since and entry_date and entry_date < since:
            continue

        ptype = p.get("pheromone_type", "NEED")
        location = p.get("location", "?")
        text = p.get("text", "")
        emitter = p.get("emitter", "?")
        reinforced = p.get("reinforcements", 0)

        label = f"[{ptype}] @{location} by {emitter}"
        if reinforced > 0:
            label += f" (+{reinforced} reinforcements)"
        entry_text = f"{label}: {text}"
        entries.append((entry_date, entry_text))

    return entries


# ‚îÄ‚îÄ Analyse et g√©n√©ration d'insights ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

_STOPWORDS = frozenset({
    "le", "la", "les", "de", "du", "des", "un", "une", "et", "ou", "en",
    "√†", "au", "aux", "pour", "par", "sur", "dans", "avec", "que", "qui",
    "est", "sont", "a", "ont", "sera", "seront", "pas", "ne", "ni", "mais",
    "the", "an", "is", "are", "was", "were", "be", "been", "being",
    "have", "has", "had", "do", "does", "did", "will", "would", "shall",
    "should", "may", "might", "can", "could", "of", "to", "in", "for",
    "on", "with", "at", "by", "from", "as", "into", "about", "between",
    "after", "before", "not", "no", "but", "or", "and", "if", "then",
    "than", "too", "very", "just", "don", "it", "its", "this", "that",
})


def _extract_keywords(text: str) -> set[str]:
    """Extrait les mots-cl√©s significatifs d'un texte (unigrams + bigrams)."""
    words = re.findall(r'[a-zA-Z√Ä-√ø]{3,}', text.lower())
    significant = [w for w in words if w not in _STOPWORDS]

    # Unigrams
    result = set(significant)

    # Bigrams ‚Äî paires de mots significatifs cons√©cutifs dans le texte original
    # On it√®re sur les mots bruts pour garder la co-localit√©
    prev_sig: str | None = None
    for w in words:
        if w in _STOPWORDS:
            prev_sig = None
            continue
        if prev_sig is not None:
            result.add(f"{prev_sig}_{w}")
        prev_sig = w

    return result


def _similarity(text_a: str, text_b: str) -> float:
    """Similarit√© cosine simplifi√©e par overlap de keywords."""
    ka = _extract_keywords(text_a)
    kb = _extract_keywords(text_b)
    if not ka or not kb:
        return 0.0
    intersection = ka & kb
    union = ka | kb
    return len(intersection) / len(union) if union else 0.0


def find_cross_connections(sources: list[DreamSource]) -> list[DreamInsight]:
    """Trouve les connexions crois√©es entre sources diff√©rentes."""
    insights: list[DreamInsight] = []

    # Comparer chaque paire de sources de types DIFF√âRENTS
    for i, src_a in enumerate(sources):
        for j, src_b in enumerate(sources):
            if j <= i or src_a.kind == src_b.kind:
                continue
            for entry_a in src_a.entries:
                for entry_b in src_b.entries:
                    sim = _similarity(entry_a, entry_b)
                    if sim >= SIMILARITY_THRESHOLD:
                        # Connexion d√©tect√©e !
                        insights.append(DreamInsight(
                            title=f"Connexion {src_a.kind} ‚Üî {src_b.kind}",
                            description=(
                                f"Pattern partag√© entre [{src_a.name}] et [{src_b.name}] :\n"
                                f"  ‚Ä¢ {entry_a[:120]}...\n"
                                f"  ‚Ä¢ {entry_b[:120]}..."
                            ),
                            sources=[src_a.name, src_b.name],
                            category="connection",
                            confidence=round(sim, 2),
                        ))

    return insights


def find_recurring_patterns(sources: list[DreamSource]) -> list[DreamInsight]:
    """D√©tecte les patterns qui reviennent fr√©quemment."""
    insights: list[DreamInsight] = []

    # Compter les keywords globalement
    keyword_freq: dict[str, list[str]] = {}  # keyword ‚Üí [source_names]
    keyword_entries: dict[str, list[str]] = {}  # keyword ‚Üí [entries]

    for src in sources:
        for entry in src.entries:
            keywords = _extract_keywords(entry)
            for kw in keywords:
                keyword_freq.setdefault(kw, []).append(src.name)
                keyword_entries.setdefault(kw, []).append(entry)

    # Trouver les keywords qui apparaissent dans ‚â• MIN_SOURCES sources diff√©rentes
    for kw, src_names in keyword_freq.items():
        unique_sources = list(set(src_names))
        if len(unique_sources) >= MIN_SOURCES and len(src_names) >= 3:
            sample_entries = keyword_entries[kw][:3]
            insights.append(DreamInsight(
                title=f"Pattern r√©current : '{kw}'",
                description=(
                    f"Le terme '{kw}' appara√Æt dans {len(unique_sources)} sources "
                    f"({len(src_names)} occurrences) :\n" +
                    "\n".join(f"  ‚Ä¢ {e[:100]}..." for e in sample_entries)
                ),
                sources=unique_sources,
                category="pattern",
                confidence=min(0.9, 0.3 + 0.1 * len(unique_sources)),
            ))

    return insights


def find_tensions(sources: list[DreamSource]) -> list[DreamInsight]:
    """D√©tecte les tensions et contradictions potentielles."""
    insights: list[DreamInsight] = []

    # Mots indicateurs de tension
    tension_markers = {
        "positive": ["toujours", "always", "must", "doit", "jamais", "never",
                      "obligatoire", "required", "important", "critical"],
        "negative": ["√©viter", "avoid", "ne pas", "never", "jamais", "danger",
                      "risque", "probl√®me", "√©chec", "fail", "broken", "cass√©"],
    }

    positive_entries: list[tuple[str, str]] = []  # (source, entry)
    negative_entries: list[tuple[str, str]] = []

    for src in sources:
        for entry in src.entries:
            entry_lower = entry.lower()
            if any(m in entry_lower for m in tension_markers["positive"]):
                positive_entries.append((src.name, entry))
            if any(m in entry_lower for m in tension_markers["negative"]):
                negative_entries.append((src.name, entry))

    # Croiser positifs et n√©gatifs sur les m√™mes sujets
    for pos_src, pos_entry in positive_entries:
        for neg_src, neg_entry in negative_entries:
            if pos_src == neg_src:
                continue
            sim = _similarity(pos_entry, neg_entry)
            if sim >= 0.3:  # Seuil plus bas pour les tensions
                insights.append(DreamInsight(
                    title=f"Tension d√©tect√©e entre {pos_src} et {neg_src}",
                    description=(
                        f"Possible contradiction sur le m√™me sujet :\n"
                        f"  ‚úÖ [{pos_src}] {pos_entry[:120]}...\n"
                        f"  ‚ùå [{neg_src}] {neg_entry[:120]}..."
                    ),
                    sources=[pos_src, neg_src],
                    category="tension",
                    confidence=round(sim + 0.1, 2),
                ))

    return insights


def find_opportunities(sources: list[DreamSource]) -> list[DreamInsight]:
    """Identifie les opportunit√©s d'am√©lioration non exploit√©es."""
    insights: list[DreamInsight] = []

    # Chercher les patterns "TODO", "√† am√©liorer", "could be better"
    opportunity_markers = [
        "todo", "√† am√©liorer", "could be better", "improvement", "optimiser",
        "refactorer", "simplifier", "automatiser", "manque", "missing",
        "pas encore", "not yet", "futur", "future", "√©ventuellement",
    ]

    for src in sources:
        for entry in src.entries:
            entry_lower = entry.lower()
            for marker in opportunity_markers:
                if marker in entry_lower:
                    insights.append(DreamInsight(
                        title=f"Opportunit√© dans {src.name}",
                        description=f"Signal d'am√©lioration : {entry[:150]}",
                        sources=[src.name],
                        category="opportunity",
                        confidence=0.5,
                        actionable=True,
                    ))
                    break  # Un seul marker suffit par entry

    return insights


# ‚îÄ‚îÄ Validation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def validate_insight(insight: DreamInsight, sources: list[DreamSource]) -> bool:
    """V√©rifie qu'un insight est ancr√© dans les sources (pas d'hallucination)."""
    # R√®gle 1 : doit avoir ‚â• 1 source existante
    if not insight.sources:
        return False

    # R√®gle 2 : les sources r√©f√©renc√©es doivent exister dans la collecte
    source_names = {s.name for s in sources}
    for ref in insight.sources:
        if ref not in source_names:
            return False

    # R√®gle 3 : confiance > 0
    if insight.confidence <= 0:
        return False

    # R√®gle 4 : description non vide
    if not insight.description or len(insight.description) < 10:
        return False

    return True


def deduplicate_insights(insights: list[DreamInsight]) -> list[DreamInsight]:
    """Supprime les insights trop similaires."""
    unique: list[DreamInsight] = []
    for ins in insights:
        is_dupe = False
        for existing in unique:
            if _similarity(ins.description, existing.description) > 0.7:
                # Garder celui avec la meilleure confiance
                if ins.confidence > existing.confidence:
                    unique.remove(existing)
                    unique.append(ins)
                is_dupe = True
                break
        if not is_dupe:
            unique.append(ins)
    return unique


# ‚îÄ‚îÄ Orchestration principale ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def dream(project_root: Path, since: str | None = None,
          agent_filter: str | None = None,
          do_validate: bool = True,
          quick: bool = False,
          _sources: list[DreamSource] | None = None) -> list[DreamInsight]:
    """Ex√©cute un cycle de dream.

    Args:
        quick: si True, mode rapide O(n) ‚Äî patterns + opportunit√©s seulement.
        _sources: sources pr√©-collect√©es (√©vite double parsing en mode CLI).
    """

    # 1. Collecte (r√©utiliser _sources si fourni)
    sources = _sources if _sources is not None else collect_sources(
        project_root, since, agent_filter)
    if not sources:
        return []

    # 2. Analyse
    all_insights: list[DreamInsight] = []
    if not quick:
        all_insights.extend(find_cross_connections(sources))
    all_insights.extend(find_recurring_patterns(sources))
    if not quick:
        all_insights.extend(find_tensions(sources))
    all_insights.extend(find_opportunities(sources))

    # 3. Validation
    if do_validate:
        all_insights = [i for i in all_insights if validate_insight(i, sources)]

    # 4. Temporal decay ‚Äî entr√©es r√©centes p√®sent plus
    apply_temporal_decay(all_insights, sources)

    # 5. D√©duplication
    all_insights = deduplicate_insights(all_insights)

    # 6. Tri par confiance d√©croissante
    all_insights.sort(key=lambda i: i.confidence, reverse=True)

    # 7. Plafonnement
    cap = QUICK_MAX_INSIGHTS if quick else MAX_INSIGHTS
    return all_insights[:cap]


def dream_quick(project_root: Path, since: str | None = None,
                agent_filter: str | None = None,
                _sources: list[DreamSource] | None = None) -> list[DreamInsight]:
    """Mode rapide O(n) ‚Äî patterns r√©currents + opportunit√©s seulement.

    Utilis√© par le post-commit auto-trigger pour ne pas ralentir le workflow.
    Skip les cross-connections O(n¬≤) et les tensions O(n¬≤).
    D√©l√®gue √† dream(quick=True) pour ne pas dupliquer la logique.
    """
    return dream(project_root, since, agent_filter,
                 do_validate=True, quick=True, _sources=_sources)


# ‚îÄ‚îÄ Dream ‚Üí Stigmergy Bridge ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

# Mapping insight category ‚Üí pheromone type
_INSIGHT_TO_PHEROMONE = {
    "tension":     "ALERT",
    "opportunity": "OPPORTUNITY",
    "connection":  "PROGRESS",
    "pattern":     "NEED",
}


def emit_to_stigmergy(insights: list[DreamInsight],
                       project_root: Path) -> int:
    """Convertit les insights dream en ph√©romones stigmergy.

    Returns le nombre de ph√©romones √©mises.
    """
    # Import dynamique pour √©viter les d√©pendances circulaires
    try:
        import importlib.util
        # Chemin co-localis√© d'abord (dream.py et stigmergy.py dans le m√™me dossier)
        sg_path = Path(__file__).parent / "stigmergy.py"
        if not sg_path.exists():
            # Fallback : chemin relatif au project_root (projet install√©)
            sg_path = project_root / "framework" / "tools" / "stigmergy.py"
        if not sg_path.exists():
            return 0

        spec = importlib.util.spec_from_file_location("stigmergy", sg_path)
        if spec is None or spec.loader is None:
            return 0
        sg = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(sg)
    except Exception:
        return 0

    board = sg.load_board(project_root)
    emitted = 0

    # Index des textes existants pour d√©duplication cross-session
    existing_texts = {p.text for p in board.pheromones if not p.resolved}

    for ins in insights:
        ptype = _INSIGHT_TO_PHEROMONE.get(ins.category, "NEED")
        # Location = premi√®re source ou "system"
        location = ins.sources[0] if ins.sources else "system/dream"
        text = f"[dream] {ins.title}: {ins.description[:200]}"

        # Skip si une ph√©romone identique est d√©j√† active sur le board
        if text in existing_texts:
            continue

        sg.emit_pheromone(
            board,
            ptype=ptype,
            location=location,
            text=text,
            emitter="dream-mode",
            tags=["auto-dream", ins.category],
            intensity=min(ins.confidence, 0.9),
        )
        existing_texts.add(text)
        emitted += 1

    if emitted > 0:
        sg.save_board(project_root, board)

    return emitted


# ‚îÄ‚îÄ Rendu ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

CATEGORY_ICONS = {
    "connection": "üîó",
    "pattern": "üîÑ",
    "tension": "‚ö°",
    "opportunity": "üí°",
}

# ‚îÄ‚îÄ Timestamp incr√©mental ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

DREAM_TIMESTAMP_FILE = "dream-last-run"


def save_last_dream_timestamp(project_root: Path) -> None:
    """Sauvegarde le timestamp du dernier dream pour le mode incr√©mental."""
    ts_dir = project_root / "_bmad" / "_memory"
    ts_dir.mkdir(parents=True, exist_ok=True)
    ts_file = ts_dir / DREAM_TIMESTAMP_FILE
    ts_file.write_text(datetime.now().strftime("%Y-%m-%d"), encoding="utf-8")


def read_last_dream_timestamp(project_root: Path) -> str | None:
    """Lit le timestamp du dernier dream. Retourne None si aucun."""
    ts_file = project_root / "_bmad" / "_memory" / DREAM_TIMESTAMP_FILE
    if not ts_file.exists():
        return None
    try:
        ts = ts_file.read_text(encoding="utf-8").strip()
        # Valider le format YYYY-MM-DD
        if len(ts) == 10 and ts[4] == "-" and ts[7] == "-":
            return ts
    except OSError:
        pass
    return None


# ‚îÄ‚îÄ Temporal Decay ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _temporal_weight(date_str: str, now: datetime | None = None) -> float:
    """Pond√©ration temporelle : r√©cent = 1.0, d√©cro√Æt avec l'√¢ge.

    Utilise une demi-vie exponentielle (DECAY_HALFLIFE_DAYS).
    Plancher √† 0.3 pour ne jamais ignorer compl√®tement une entr√©e.
    Retourne 1.0 si date invalide ou vide (pas de p√©nalit√©).
    """
    if not date_str or len(date_str) < 10:
        return 1.0
    try:
        entry_date = datetime(int(date_str[:4]), int(date_str[5:7]),
                              int(date_str[8:10]))
    except (ValueError, IndexError):
        return 1.0
    ref = now or datetime.now()
    age_days = max(0, (ref - entry_date).days)
    if age_days == 0:
        return 1.0
    # D√©croissance exponentielle : weight = 2^(-age/halflife)
    import math
    weight = math.pow(2.0, -age_days / DECAY_HALFLIFE_DAYS)
    return max(0.3, round(weight, 3))


def apply_temporal_decay(insights: list[DreamInsight],
                         sources: list[DreamSource],
                         now: datetime | None = None) -> None:
    """Applique un facteur de d√©croissance temporelle √† la confiance des insights.

    Pour chaque insight, calcule le poids moyen des dates de ses sources
    contributrices, puis multiplie la confiance.
    Modifie les insights in-place.
    """
    # Index source_name ‚Üí dates
    source_dates: dict[str, list[str]] = {}
    for src in sources:
        source_dates[src.name] = src.dates

    for ins in insights:
        weights: list[float] = []
        for src_name in ins.sources:
            dates = source_dates.get(src_name, [])
            if dates:
                # Poids moyen des entr√©es de cette source
                src_weights = [_temporal_weight(d, now) for d in dates if d]
                if src_weights:
                    weights.append(sum(src_weights) / len(src_weights))
        if weights:
            avg_weight = sum(weights) / len(weights)
            ins.confidence = round(ins.confidence * avg_weight, 3)


# ‚îÄ‚îÄ Dream Memory ‚Äî persistence tracking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _insight_signature(insight: DreamInsight) -> str:
    """Signature stable d'un insight pour tracking cross-session.

    Combine cat√©gorie + titre normalis√©. Les variations mineures de
    description ne changent pas la signature.
    """
    norm_title = re.sub(r'[^a-z0-9]', '', insight.title.lower())
    return f"{insight.category}:{norm_title}"


def load_dream_memory(project_root: Path) -> dict:
    """Charge dream-memory.json. Retourne {} si inexistant."""
    mem_path = project_root / "_bmad-output" / DREAM_MEMORY_FILE
    if not mem_path.exists():
        return {}
    try:
        return json.loads(mem_path.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return {}


def save_dream_memory(project_root: Path, memory: dict) -> None:
    """Sauvegarde dream-memory.json."""
    mem_path = project_root / "_bmad-output" / DREAM_MEMORY_FILE
    mem_path.parent.mkdir(parents=True, exist_ok=True)
    mem_path.write_text(json.dumps(memory, indent=2, ensure_ascii=False),
                        encoding="utf-8")


def update_dream_memory(insights: list[DreamInsight],
                        memory: dict) -> dict[str, list[DreamInsight]]:
    """Met √† jour la m√©moire et classifie les insights.

    Retourne {"new": [...], "persistent": [...], "resolved": [sig, ...]}
    - new : insights jamais vus
    - persistent : insights vus dans ‚â•2 sessions cons√©cutives (boost confiance)
    - resolved : signatures qui √©taient dans la m√©moire mais plus dans ce dream
    """
    now_str = datetime.now().strftime("%Y-%m-%d")
    seen_sigs: set[str] = set()
    new_insights: list[DreamInsight] = []
    persistent_insights: list[DreamInsight] = []

    entries = memory.get("insights", {})

    for ins in insights:
        sig = _insight_signature(ins)
        seen_sigs.add(sig)

        if sig in entries:
            # D√©j√† vu ‚Äî incr√©menter
            entries[sig]["seen_count"] += 1
            entries[sig]["last_seen"] = now_str
            entries[sig]["confidence"] = ins.confidence
            # Boost confiance pour la persistence
            ins.confidence = min(1.0, round(
                ins.confidence + PERSISTENCE_BOOST, 3))
            persistent_insights.append(ins)
        else:
            # Nouveau
            entries[sig] = {
                "title": ins.title,
                "category": ins.category,
                "first_seen": now_str,
                "last_seen": now_str,
                "seen_count": 1,
                "confidence": ins.confidence,
            }
            new_insights.append(ins)

    # Insights r√©solus : √©taient dans la m√©moire (seen_count > 1), absents maintenant
    resolved_sigs: list[str] = []
    for sig, entry in list(entries.items()):
        if sig not in seen_sigs:
            if entry.get("seen_count", 0) >= 2:
                resolved_sigs.append(sig)
            # Garder en m√©moire mais marquer comme stale
            entry["stale"] = True

    memory["insights"] = entries
    memory["last_dream"] = now_str
    memory["total_dreams"] = memory.get("total_dreams", 0) + 1

    return {
        "new": new_insights,
        "persistent": persistent_insights,
        "resolved": resolved_sigs,
    }


def render_journal(insights: list[DreamInsight], sources: list[DreamSource],
                   project_root: Path, since: str | None = None,
                   dream_diff: dict[str, list] | None = None) -> str:
    """G√©n√®re le dream-journal.md en Markdown."""
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    total_entries = sum(len(s.entries) for s in sources)

    lines = [
        f"# üåô BMAD Dream Journal ‚Äî {now}",
        "",
        f"> Consolidation hors-session ‚Äî {len(sources)} sources, {total_entries} entr√©es analys√©es",
    ]
    if since:
        lines.append(f"> P√©riode : depuis {since}")
    lines.extend(["", "---", ""])

    # Dream Diff (si disponible)
    if dream_diff:
        new_count = len(dream_diff.get("new", []))
        persist_count = len(dream_diff.get("persistent", []))
        resolved_count = len(dream_diff.get("resolved", []))
        if new_count or persist_count or resolved_count:
            lines.append("## üîÄ Dream Diff")
            lines.append("")
            if persist_count:
                lines.append(f"**üîÅ Persistants** ({persist_count}) ‚Äî insights confirm√©s sur plusieurs sessions :")
                for ins in dream_diff["persistent"]:
                    lines.append(f"- ‚¨ÜÔ∏è {ins.title} ({ins.confidence:.0%})")
                lines.append("")
            if new_count:
                lines.append(f"**üÜï Nouveaux** ({new_count}) :")
                for ins in dream_diff["new"]:
                    lines.append(f"- {ins.title}")
                lines.append("")
            if resolved_count:
                lines.append(f"**‚úÖ R√©solus** ({resolved_count}) ‚Äî n'apparaissent plus :")
                for sig in dream_diff["resolved"]:
                    lines.append(f"- ~{sig}~")
                lines.append("")
            lines.extend(["---", ""])

    # R√©sum√© par cat√©gorie
    by_cat: dict[str, list[DreamInsight]] = {}
    for ins in insights:
        by_cat.setdefault(ins.category, []).append(ins)

    lines.append("## üìä R√©sum√©")
    lines.append("")
    lines.append("| Cat√©gorie | Count | Confiance moy. |")
    lines.append("|-----------|-------|----------------|")
    for cat, cat_insights in sorted(by_cat.items()):
        icon = CATEGORY_ICONS.get(cat, "‚ùì")
        avg_conf = sum(i.confidence for i in cat_insights) / len(cat_insights)
        lines.append(f"| {icon} {cat} | {len(cat_insights)} | {avg_conf:.0%} |")
    lines.extend(["", "---", ""])

    # D√©tail des insights
    lines.append("## üß† Insights")
    lines.append("")
    for idx, ins in enumerate(insights, 1):
        icon = CATEGORY_ICONS.get(ins.category, "‚ùì")
        conf_bar = "‚ñà" * int(ins.confidence * 10) + "‚ñë" * (10 - int(ins.confidence * 10))
        lines.append(f"### {icon} {idx}. {ins.title}")
        lines.append("")
        lines.append(f"**Confiance** : `{conf_bar}` {ins.confidence:.0%}")
        lines.append(f"**Sources** : {', '.join(ins.sources)}")
        if ins.actionable:
            lines.append("**üéØ Actionable**")
        lines.append("")
        lines.append(ins.description)
        lines.append("")

    # Sources analys√©es
    lines.extend(["---", "", "## üìö Sources analys√©es", ""])
    for src in sources:
        lines.append(f"- **{src.name}** ({src.kind}) ‚Äî {len(src.entries)} entr√©es")
    lines.append("")

    return "\n".join(lines)


def write_journal(content: str, project_root: Path, dry_run: bool = False) -> Path:
    """√âcrit le journal dans _bmad-output/dream-journal.md."""
    output_dir = project_root / "_bmad-output"
    output_dir.mkdir(parents=True, exist_ok=True)
    journal_path = output_dir / "dream-journal.md"

    if dry_run:
        print(content)
        return journal_path

    # Archiver le journal pr√©c√©dent s'il existe
    if journal_path.exists():
        archive_dir = output_dir / "dream-archives"
        archive_dir.mkdir(exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d-%H%M")
        archive_path = archive_dir / f"dream-journal-{ts}.md"
        journal_path.rename(archive_path)

    journal_path.write_text(content, encoding="utf-8")
    return journal_path


# ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main():
    parser = argparse.ArgumentParser(
        description="BMAD Dream Mode ‚Äî consolidation hors-session et insights √©mergents",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("--project-root", default=".", help="Racine du projet BMAD")
    parser.add_argument("--since", default=None,
                        help="Date d√©but (YYYY-MM-DD) ou 'auto' pour depuis le dernier dream")
    parser.add_argument("--agent", default=None, help="Filtrer par agent")
    parser.add_argument("--validate", action="store_true", help="Valider les insights")
    parser.add_argument("--dry-run", action="store_true", help="Afficher sans √©crire")
    parser.add_argument("--json", action="store_true", help="Sortie JSON")
    parser.add_argument("--quick", action="store_true",
                        help="Mode rapide O(n) ‚Äî patterns + opportunit√©s seulement")
    parser.add_argument("--emit", action="store_true",
                        help="√âmettre les insights comme ph√©romones stigmergy")

    args = parser.parse_args()
    project_root = Path(args.project_root).resolve()

    # R√©soudre --since auto
    since = args.since
    if since == "auto":
        since = read_last_dream_timestamp(project_root)

    # Collecte unique (partag√©e entre affichage et dream)
    sources = collect_sources(project_root, since, args.agent)
    if not sources:
        print("üí§ Aucune source de m√©moire trouv√©e ‚Äî rien √† r√™ver.")
        sys.exit(0)

    total_entries = sum(len(s.entries) for s in sources)
    mode_label = "Quick" if args.quick else "Dream"
    print(f"üåô {mode_label} Mode ‚Äî {len(sources)} sources, {total_entries} entr√©es")
    if since:
        print(f"   Depuis : {since}")
    print()

    # Dream (quick ou full) ‚Äî r√©utiliser les sources pr√©-collect√©es
    if args.quick:
        insights = dream_quick(project_root, since, args.agent,
                               _sources=sources)
    else:
        insights = dream(project_root, since, args.agent, args.validate,
                         _sources=sources)

    if not insights:
        print("üò¥ Aucun insight √©mergent d√©tect√©. Le syst√®me est coh√©rent.")
        sys.exit(0)

    # Dream Memory ‚Äî tracking persistence cross-session
    dream_diff = None
    if not args.dry_run:
        memory = load_dream_memory(project_root)
        dream_diff = update_dream_memory(insights, memory)
        save_dream_memory(project_root, memory)

        new_count = len(dream_diff.get("new", []))
        persist_count = len(dream_diff.get("persistent", []))
        resolved_count = len(dream_diff.get("resolved", []))
        if persist_count:
            print(f"üîÅ {persist_count} insight(s) persistant(s) (confiance boost√©e)")
        if new_count:
            print(f"üÜï {new_count} nouvel(s) insight(s)")
        if resolved_count:
            print(f"‚úÖ {resolved_count} insight(s) r√©solu(s) (disparus)")
        if persist_count or new_count or resolved_count:
            print()

    # Emit ‚Üí stigmergy
    if args.emit:
        count = emit_to_stigmergy(insights, project_root)
        if count > 0:
            print(f"üêú {count} insight(s) √©mis comme ph√©romones stigmergy")
            print()

    # Sortie JSON
    if args.json:
        data = [
            {
                "title": i.title,
                "description": i.description,
                "sources": i.sources,
                "category": i.category,
                "confidence": i.confidence,
                "actionable": i.actionable,
            }
            for i in insights
        ]
        print(json.dumps(data, indent=2, ensure_ascii=False))
        sys.exit(0)

    # Rendu Markdown (avec dream diff)
    journal = render_journal(insights, sources, project_root, since,
                             dream_diff=dream_diff)
    output_path = write_journal(journal, project_root, args.dry_run)

    if not args.dry_run:
        print(f"‚úÖ {len(insights)} insights √©crits dans {output_path}")
        # Sauver le timestamp pour le mode incr√©mental
        save_last_dream_timestamp(project_root)
        print()
        # Preview compact
        for idx, ins in enumerate(insights[:5], 1):
            icon = CATEGORY_ICONS.get(ins.category, "‚ùì")
            print(f"  {icon} {idx}. {ins.title} ({ins.confidence:.0%})")
        if len(insights) > 5:
            print(f"  ... et {len(insights) - 5} de plus dans le journal")


if __name__ == "__main__":
    main()
