#!/usr/bin/env python3
"""
memory-lint.py â€” Linter de cohÃ©rence mÃ©moire BMAD.
=====================================================

Valide la cohÃ©rence croisÃ©e des fichiers mÃ©moire du projet :
  - Contradictions inter-fichiers (learnings vs decisions, decisions vs trace)
  - EntrÃ©es orphelines (dÃ©cision rÃ©fÃ©rencÃ©e dans trace mais absente)
  - Doublons inter-fichiers (mÃªme entrÃ©e copiÃ©e dans plusieurs fichiers)
  - RÃ©fÃ©rences cassÃ©es (fichier source mentionnÃ© mais inexistant)
  - IncohÃ©rences chronologiques (entrÃ©e datÃ©e avant la crÃ©ation du fichier)

Ã‰met un rapport structurÃ© et peut optionnellement crÃ©er des phÃ©romones
stigmergy pour les problÃ¨mes critiques.

Usage :
  python3 memory-lint.py --project-root .
  python3 memory-lint.py --project-root . --json
  python3 memory-lint.py --project-root . --emit     # Ã©mettre vers stigmergy
  python3 memory-lint.py --project-root . --fix       # suggestions de fix

Stdlib only â€” aucune dÃ©pendance externe.
"""

from __future__ import annotations

import argparse
import json
import re
import sys
from dataclasses import dataclass, field
from pathlib import Path

# â”€â”€ Constantes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

LINT_VERSION = "1.0.0"

# Seuil de similaritÃ© pour la dÃ©tection de doublons
DUPLICATE_THRESHOLD = 0.75

# Seuil de similaritÃ© pour la dÃ©tection de contradictions
CONTRADICTION_THRESHOLD = 0.30

# Marqueurs de contradiction (mÃªme logique que dream.py)
POSITIVE_MARKERS = frozenset({
    "toujours", "always", "must", "doit", "jamais", "never",
    "obligatoire", "required", "important", "critical",
})

NEGATIVE_MARKERS = frozenset({
    "Ã©viter", "avoid", "ne pas", "danger",
    "risque", "problÃ¨me", "Ã©chec", "fail", "broken", "cassÃ©",
})

# Severity levels
SEVERITY_ERROR = "error"      # Contradiction avÃ©rÃ©e, rÃ©fÃ©rence cassÃ©e
SEVERITY_WARNING = "warning"  # Doublon probable, orphelin potentiel
SEVERITY_INFO = "info"        # Suggestion d'amÃ©lioration


# â”€â”€ Data classes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class LintIssue:
    """Un problÃ¨me dÃ©tectÃ© par le linter mÃ©moire."""
    issue_id: str
    severity: str          # error | warning | info
    category: str          # contradiction | orphan | duplicate | broken-ref | chrono
    title: str
    description: str
    files: list[str]       # fichiers impliquÃ©s
    entries: list[str] = field(default_factory=list)  # entrÃ©es concernÃ©es
    fix_suggestion: str = ""


@dataclass
class MemoryFile:
    """Un fichier mÃ©moire parsÃ©."""
    path: str              # chemin relatif depuis _bmad/_memory
    kind: str              # learnings | decisions | trace | failure-museum | shared-context | contradictions
    entries: list[tuple[str, str]] = field(default_factory=list)  # (date, text)


@dataclass
class LintReport:
    """Rapport complet du linter."""
    version: str = LINT_VERSION
    files_scanned: int = 0
    entries_scanned: int = 0
    issues: list[LintIssue] = field(default_factory=list)

    @property
    def error_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == SEVERITY_ERROR)

    @property
    def warning_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == SEVERITY_WARNING)

    @property
    def info_count(self) -> int:
        return sum(1 for i in self.issues if i.severity == SEVERITY_INFO)


# â”€â”€ Parsing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_DATE_PATTERN = re.compile(r'\[(\d{4}-\d{2}-\d{2})')
_TRACE_PATTERN = re.compile(
    r'\[(\d{4}-\d{2}-\d{2})[^\]]*\]\s*\[(\w+)\]\s*\[([^\]]+)\]\s*(.*)'
)


def _parse_markdown_entries(path: Path) -> list[tuple[str, str]]:
    """Parse un fichier markdown en (date, text)."""
    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return []

    entries: list[tuple[str, str]] = []
    for line in content.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        match = _DATE_PATTERN.search(line)
        entry_date = match.group(1) if match else ""
        if line.startswith("- ") or line.startswith("* "):
            entries.append((entry_date, line[2:].strip()))
    return entries


def _parse_trace_entries(path: Path) -> list[tuple[str, str]]:
    """Parse BMAD_TRACE.md en (date, text)."""
    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return []

    entries: list[tuple[str, str]] = []
    for line in content.splitlines():
        m = _TRACE_PATTERN.match(line.strip())
        if m:
            date, level, agent, payload = m.groups()
            entries.append((date, f"[{agent}] [{level}] {payload}"))
    return entries


def collect_memory_files(project_root: Path) -> list[MemoryFile]:
    """Collecte tous les fichiers mÃ©moire du projet."""
    files: list[MemoryFile] = []
    memory_dir = project_root / "_bmad" / "_memory"

    # Learnings
    learnings_dir = memory_dir / "agent-learnings"
    if learnings_dir.exists():
        for f in sorted(learnings_dir.glob("*.md")):
            entries = _parse_markdown_entries(f)
            if entries:
                files.append(MemoryFile(
                    path=f"learnings/{f.name}", kind="learnings",
                    entries=entries,
                ))

    # Decisions log
    decisions_file = memory_dir / "decisions-log.md"
    if decisions_file.exists():
        entries = _parse_markdown_entries(decisions_file)
        if entries:
            files.append(MemoryFile(
                path="decisions-log.md", kind="decisions",
                entries=entries,
            ))

    # BMAD_TRACE
    trace_file = project_root / "_bmad-output" / "BMAD_TRACE.md"
    if trace_file.exists():
        entries = _parse_trace_entries(trace_file)
        if entries:
            files.append(MemoryFile(
                path="BMAD_TRACE.md", kind="trace",
                entries=entries,
            ))

    # Failure Museum
    failure_file = memory_dir / "failure-museum.md"
    if failure_file.exists():
        entries = _parse_markdown_entries(failure_file)
        if entries:
            files.append(MemoryFile(
                path="failure-museum.md", kind="failure-museum",
                entries=entries,
            ))

    # Contradiction log
    contradiction_file = memory_dir / "contradiction-log.md"
    if contradiction_file.exists():
        entries = _parse_markdown_entries(contradiction_file)
        if entries:
            files.append(MemoryFile(
                path="contradiction-log.md", kind="contradictions",
                entries=entries,
            ))

    # Shared context
    shared_file = memory_dir / "shared-context.md"
    if shared_file.exists():
        entries = _parse_markdown_entries(shared_file)
        if entries:
            files.append(MemoryFile(
                path="shared-context.md", kind="shared-context",
                entries=entries,
            ))

    return files


# â”€â”€ Analyse keywords â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_STOPWORDS = frozenset({
    "le", "la", "les", "de", "du", "des", "un", "une", "et", "ou", "en",
    "Ã ", "au", "aux", "pour", "par", "sur", "dans", "avec", "que", "qui",
    "est", "sont", "a", "ont", "sera", "seront", "pas", "ne", "ni", "mais",
    "the", "an", "is", "are", "was", "were", "be", "been", "being",
    "have", "has", "had", "do", "does", "did", "will", "would", "shall",
    "should", "may", "might", "can", "could", "of", "to", "in", "for",
    "on", "with", "at", "by", "from", "as", "into", "about", "between",
    "after", "before", "not", "no", "but", "or", "and", "if", "then",
    "than", "too", "very", "just", "don", "it", "its", "this", "that",
})


def _extract_keywords(text: str) -> set[str]:
    """Extrait les mots-clÃ©s significatifs d'un texte."""
    words = re.findall(r'[a-zA-ZÃ€-Ã¿]{3,}', text.lower())
    return {w for w in words if w not in _STOPWORDS}


def _similarity(text_a: str, text_b: str) -> float:
    """SimilaritÃ© Jaccard sur les keywords."""
    ka = _extract_keywords(text_a)
    kb = _extract_keywords(text_b)
    if not ka or not kb:
        return 0.0
    intersection = ka & kb
    union = ka | kb
    return len(intersection) / len(union) if union else 0.0


def _has_polarity(text: str) -> tuple[bool, bool]:
    """Retourne (is_positive, is_negative) selon les marqueurs."""
    text_lower = text.lower()
    is_pos = any(m in text_lower for m in POSITIVE_MARKERS)
    is_neg = any(m in text_lower for m in NEGATIVE_MARKERS)
    return is_pos, is_neg


# â”€â”€ Checks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_issue_counter = 0


def _next_id() -> str:
    """GÃ©nÃ¨re un ID court pour les issues."""
    global _issue_counter  # noqa: PLW0603
    _issue_counter += 1
    return f"ML-{_issue_counter:03d}"


def check_contradictions(files: list[MemoryFile]) -> list[LintIssue]:
    """DÃ©tecte les contradictions entre fichiers mÃ©moire.

    Une contradiction = deux entrÃ©es de fichiers DIFFÃ‰RENTS sur le mÃªme sujet
    avec des polaritÃ©s opposÃ©es (positive vs nÃ©gative).
    """
    issues: list[LintIssue] = []

    positive_entries: list[tuple[str, str, str]] = []  # (file, date, text)
    negative_entries: list[tuple[str, str, str]] = []

    for mf in files:
        for date, text in mf.entries:
            is_pos, is_neg = _has_polarity(text)
            if is_pos:
                positive_entries.append((mf.path, date, text))
            if is_neg:
                negative_entries.append((mf.path, date, text))

    for pos_file, _pos_date, pos_text in positive_entries:
        for neg_file, _neg_date, neg_text in negative_entries:
            if pos_file == neg_file:
                continue
            sim = _similarity(pos_text, neg_text)
            if sim >= CONTRADICTION_THRESHOLD:
                issues.append(LintIssue(
                    issue_id=_next_id(),
                    severity=SEVERITY_ERROR,
                    category="contradiction",
                    title=f"Contradiction entre {pos_file} et {neg_file}",
                    description=(
                        f"PolaritÃ© positive/nÃ©gative sur un sujet similaire "
                        f"(similaritÃ© : {sim:.0%})"
                    ),
                    files=[pos_file, neg_file],
                    entries=[pos_text[:120], neg_text[:120]],
                    fix_suggestion=(
                        "VÃ©rifier si les deux entrÃ©es sont compatibles. "
                        "Si oui, clarifier le contexte. Si non, rÃ©soudre "
                        "et documenter dans contradiction-log.md."
                    ),
                ))

    return issues


def check_duplicates(files: list[MemoryFile]) -> list[LintIssue]:
    """DÃ©tecte les doublons inter-fichiers.

    Un doublon = mÃªme entrÃ©e (ou trÃ¨s similaire) dans 2+ fichiers diffÃ©rents.
    """
    issues: list[LintIssue] = []
    seen: list[tuple[str, str]] = []  # (file, text)

    for mf in files:
        for _date, text in mf.entries:
            for prev_file, prev_text in seen:
                if prev_file == mf.path:
                    continue
                if _similarity(text, prev_text) >= DUPLICATE_THRESHOLD:
                    issues.append(LintIssue(
                        issue_id=_next_id(),
                        severity=SEVERITY_WARNING,
                        category="duplicate",
                        title=f"Doublon entre {mf.path} et {prev_file}",
                        description="EntrÃ©es trÃ¨s similaires dans deux fichiers mÃ©moire",
                        files=[mf.path, prev_file],
                        entries=[text[:120], prev_text[:120]],
                        fix_suggestion=(
                            "Garder l'entrÃ©e dans le fichier le plus appropriÃ©. "
                            "Supprimer le doublon de l'autre fichier."
                        ),
                    ))
            seen.append((mf.path, text))

    return issues


def check_orphan_decisions(files: list[MemoryFile]) -> list[LintIssue]:
    """DÃ©tecte les dÃ©cisions rÃ©fÃ©rencÃ©es dans trace mais absentes du decisions-log.

    Une dÃ©cision orpheline = BMAD_TRACE contient [DECISION] mais aucune entrÃ©e
    similaire dans decisions-log.md.
    """
    issues: list[LintIssue] = []

    # Trouver les fichiers concernÃ©s
    trace_file = next((f for f in files if f.kind == "trace"), None)
    decision_file = next((f for f in files if f.kind == "decisions"), None)

    if not trace_file or not decision_file:
        return issues

    # Extraire les dÃ©cisions depuis la trace
    trace_decisions = [
        (date, text) for date, text in trace_file.entries
        if "[DECISION]" in text
    ]

    if not trace_decisions:
        return issues

    # Pour chaque dÃ©cision de la trace, chercher une correspondance
    decision_texts = [text for _, text in decision_file.entries]

    for date, trace_text in trace_decisions:
        found = False
        for dec_text in decision_texts:
            if _similarity(trace_text, dec_text) >= 0.3:
                found = True
                break
        if not found:
            issues.append(LintIssue(
                issue_id=_next_id(),
                severity=SEVERITY_WARNING,
                category="orphan",
                title=f"DÃ©cision orpheline dans BMAD_TRACE [{date}]",
                description=(
                    "Une dÃ©cision enregistrÃ©e dans la trace n'a pas "
                    "d'entrÃ©e correspondante dans decisions-log.md"
                ),
                files=["BMAD_TRACE.md", "decisions-log.md"],
                entries=[trace_text[:150]],
                fix_suggestion=(
                    "Ajouter cette dÃ©cision dans decisions-log.md pour "
                    "assurer la traÃ§abilitÃ© complÃ¨te."
                ),
            ))

    return issues


def check_failure_without_lesson(files: list[MemoryFile]) -> list[LintIssue]:
    """DÃ©tecte les failures sans leÃ§on associÃ©e dans les learnings.

    Un failure non capitalisÃ© = entry dans failure-museum sans entrÃ©e
    correspondante dans aucun learnings/*.md.
    """
    issues: list[LintIssue] = []

    failure_file = next((f for f in files if f.kind == "failure-museum"), None)
    learning_files = [f for f in files if f.kind == "learnings"]

    if not failure_file or not learning_files:
        return issues

    all_learning_texts = [
        text for lf in learning_files for _, text in lf.entries
    ]

    for date, failure_text in failure_file.entries:
        found = False
        for learn_text in all_learning_texts:
            if _similarity(failure_text, learn_text) >= 0.25:
                found = True
                break
        if not found:
            issues.append(LintIssue(
                issue_id=_next_id(),
                severity=SEVERITY_INFO,
                category="orphan",
                title=f"Failure non capitalisÃ© [{date}]",
                description=(
                    "Un Ã©chec dans le failure-museum n'a pas de leÃ§on "
                    "correspondante dans les learnings."
                ),
                files=["failure-museum.md"],
                entries=[failure_text[:150]],
                fix_suggestion=(
                    "Extraire la leÃ§on apprise de cet Ã©chec et l'ajouter "
                    "dans le fichier learnings de l'agent concernÃ©."
                ),
            ))

    return issues


def check_chronological_consistency(files: list[MemoryFile]) -> list[LintIssue]:
    """DÃ©tecte les incohÃ©rences chronologiques dans chaque fichier.

    Les entrÃ©es avec dates devraient Ãªtre en ordre dÃ©croissant (plus rÃ©cente en haut)
    ou croissant. On dÃ©tecte les sauts de date incohÃ©rents.
    """
    issues: list[LintIssue] = []

    for mf in files:
        dated_entries = [(d, t) for d, t in mf.entries if d]
        if len(dated_entries) < 2:
            continue

        dates = [d for d, _ in dated_entries]

        # Calculer si c'est ascendant ou descendant
        asc_count = sum(1 for i in range(1, len(dates)) if dates[i] >= dates[i - 1])
        desc_count = sum(1 for i in range(1, len(dates)) if dates[i] <= dates[i - 1])

        total = len(dates) - 1
        if total == 0:
            continue

        # Seuil : si ni clairement asc ni desc (< 70% d'un sens)
        max_dir = max(asc_count, desc_count)
        if max_dir / total < 0.7 and total >= 3:
            issues.append(LintIssue(
                issue_id=_next_id(),
                severity=SEVERITY_INFO,
                category="chrono",
                title=f"Dates dÃ©sordonnÃ©es dans {mf.path}",
                description=(
                    f"{total + 1} entrÃ©es datÃ©es ne suivent pas un ordre "
                    f"chronologique cohÃ©rent (asc: {asc_count}, desc: {desc_count})"
                ),
                files=[mf.path],
                fix_suggestion="RÃ©organiser les entrÃ©es par date.",
            ))

    return issues


# â”€â”€ Orchestration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def lint_memory(project_root: Path) -> LintReport:
    """ExÃ©cute toutes les vÃ©rifications de cohÃ©rence mÃ©moire.

    Retourne un LintReport avec tous les problÃ¨mes dÃ©tectÃ©s.
    """
    global _issue_counter  # noqa: PLW0603
    _issue_counter = 0

    files = collect_memory_files(project_root)

    report = LintReport(
        files_scanned=len(files),
        entries_scanned=sum(len(f.entries) for f in files),
    )

    # ExÃ©cuter tous les checks
    report.issues.extend(check_contradictions(files))
    report.issues.extend(check_duplicates(files))
    report.issues.extend(check_orphan_decisions(files))
    report.issues.extend(check_failure_without_lesson(files))
    report.issues.extend(check_chronological_consistency(files))

    # Trier : errors > warnings > info
    severity_order = {SEVERITY_ERROR: 0, SEVERITY_WARNING: 1, SEVERITY_INFO: 2}
    report.issues.sort(key=lambda i: severity_order.get(i.severity, 9))

    return report


# â”€â”€ Ã‰mission Stigmergy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def emit_to_stigmergy(report: LintReport, project_root: Path) -> int:
    """Ã‰met les issues critiques comme phÃ©romones stigmergy.

    Seuls les errors sont Ã©mis (contradictions, refs cassÃ©es).
    Retourne le nombre de phÃ©romones Ã©mises.
    """
    try:
        import importlib.util
        sg_path = Path(__file__).parent / "stigmergy.py"
        if not sg_path.exists():
            return 0
        spec = importlib.util.spec_from_file_location("stigmergy", sg_path)
        if spec is None or spec.loader is None:
            return 0
        sg = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(sg)
    except Exception:
        return 0

    board = sg.load_board(project_root)
    existing_texts = {p.text for p in board.pheromones if not p.resolved}
    emitted = 0

    for issue in report.issues:
        if issue.severity != SEVERITY_ERROR:
            continue

        text = f"[memory-lint] {issue.title}: {issue.description[:200]}"
        if text in existing_texts:
            continue

        sg.emit_pheromone(
            board,
            ptype="ALERT",
            location=issue.files[0] if issue.files else "memory",
            text=text,
            emitter="memory-lint",
            tags=["auto-lint", issue.category],
            intensity=0.8,
        )
        existing_texts.add(text)
        emitted += 1

    if emitted > 0:
        sg.save_board(project_root, board)

    return emitted


# â”€â”€ Rendu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SEVERITY_ICONS = {
    SEVERITY_ERROR: "ğŸ”´",
    SEVERITY_WARNING: "ğŸŸ¡",
    SEVERITY_INFO: "ğŸ”µ",
}

CATEGORY_ICONS = {
    "contradiction": "âš¡",
    "duplicate": "ğŸ“‹",
    "orphan": "ğŸ‘»",
    "broken-ref": "ğŸ”—",
    "chrono": "ğŸ“…",
}


def render_report(report: LintReport, show_fix: bool = False) -> str:
    """Rend le rapport en texte formatÃ©."""
    lines = [
        "ğŸ” BMAD Memory Lint Report",
        f"   Fichiers scannÃ©s : {report.files_scanned}",
        f"   EntrÃ©es analysÃ©es : {report.entries_scanned}",
        "",
    ]

    if not report.issues:
        lines.append("âœ… Aucun problÃ¨me dÃ©tectÃ© â€” mÃ©moire cohÃ©rente.")
        return "\n".join(lines)

    lines.append(
        f"   ProblÃ¨mes : {report.error_count} erreurs, "
        f"{report.warning_count} warnings, {report.info_count} infos"
    )
    lines.extend(["", "---", ""])

    for issue in report.issues:
        sev_icon = SEVERITY_ICONS.get(issue.severity, "â“")
        cat_icon = CATEGORY_ICONS.get(issue.category, "")
        lines.append(
            f"{sev_icon} {cat_icon} [{issue.issue_id}] {issue.title}"
        )
        lines.append(f"   {issue.description}")
        if issue.entries:
            for entry in issue.entries[:2]:
                lines.append(f"     â†’ {entry}")
        if show_fix and issue.fix_suggestion:
            lines.append(f"   ğŸ’¡ Fix : {issue.fix_suggestion}")
        lines.append("")

    return "\n".join(lines)


def report_to_dict(report: LintReport) -> dict:
    """Convertit le rapport en dict JSON."""
    return {
        "version": report.version,
        "files_scanned": report.files_scanned,
        "entries_scanned": report.entries_scanned,
        "summary": {
            "errors": report.error_count,
            "warnings": report.warning_count,
            "info": report.info_count,
            "total": len(report.issues),
        },
        "issues": [
            {
                "issue_id": i.issue_id,
                "severity": i.severity,
                "category": i.category,
                "title": i.title,
                "description": i.description,
                "files": i.files,
                "entries": i.entries,
                "fix_suggestion": i.fix_suggestion,
            }
            for i in report.issues
        ],
    }


# â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(
        description="BMAD Memory Lint â€” vÃ©rification de cohÃ©rence mÃ©moire",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("--project-root", default=".",
                        help="Racine du projet BMAD")
    parser.add_argument("--json", action="store_true",
                        help="Sortie JSON")
    parser.add_argument("--fix", action="store_true",
                        help="Afficher les suggestions de fix")
    parser.add_argument("--emit", action="store_true",
                        help="Ã‰mettre les erreurs comme phÃ©romones stigmergy")

    args = parser.parse_args()
    project_root = Path(args.project_root).resolve()

    report = lint_memory(project_root)

    if args.json:
        print(json.dumps(report_to_dict(report), indent=2, ensure_ascii=False))
        sys.exit(0)

    print(render_report(report, show_fix=args.fix))

    if args.emit and report.error_count > 0:
        count = emit_to_stigmergy(report, project_root)
        if count > 0:
            print(f"ğŸœ {count} erreur(s) Ã©mise(s) comme phÃ©romones stigmergy")

    # Exit code : 1 si erreurs, 0 sinon
    sys.exit(1 if report.error_count > 0 else 0)


if __name__ == "__main__":
    main()
