#!/usr/bin/env python3
"""
antifragile-score.py ‚Äî Score d'Anti-Fragilit√© du syst√®me BMAD.
===============================================================

Mesure comment le syst√®me apprend et s'am√©liore √† partir de ses √©checs.
Croise Failure Museum, SIL signals, contradictions, learnings et decisions
pour produire un score composite 0-100 :

  - < 30 : FRAGILE   ‚Äî le syst√®me casse et n'apprend pas
  - 30-60 : ROBUST   ‚Äî le syst√®me survit mais ne s'am√©liore pas
  - 60-100: ANTIFRAGILE ‚Äî le syst√®me s'am√©liore sous le stress

Usage :
  python3 antifragile-score.py --project-root .
  python3 antifragile-score.py --project-root . --since 2026-01-01
  python3 antifragile-score.py --project-root . --detail
  python3 antifragile-score.py --project-root . --trend
  python3 antifragile-score.py --project-root . --json

Stdlib only ‚Äî aucune d√©pendance externe.
"""

import argparse
import json
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional
from dataclasses import dataclass, field


# ‚îÄ‚îÄ Constantes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

FRAGILE_THRESHOLD = 30
ROBUST_THRESHOLD = 60
HISTORY_FILE = "antifragile-history.json"

# Pond√©ration des dimensions (total = 1.0)
WEIGHTS = {
    "recovery": 0.25,       # Taux de r√©cup√©ration (failures ‚Üí r√®gles)
    "learning_velocity": 0.20,  # Vitesse d'apprentissage
    "contradiction_resolution": 0.15,  # R√©solution des contradictions
    "signal_trend": 0.15,   # Tendance des signaux SIL
    "decision_quality": 0.10,  # Qualit√© des d√©cisions
    "pattern_recurrence": 0.15,  # Non-r√©currence des patterns d'√©chec
}

# Cat√©gories du Failure Museum
FAILURE_CATEGORIES = [
    "CC-FAIL", "WRONG-ASSUMPTION", "CONTEXT-LOSS",
    "HALLUCINATION", "ARCH-MISTAKE", "PROCESS-SKIP",
]

# Marqueurs SIL
SIL_MARKERS = {
    "cc_fail": ["cc fail", "cc_fail", "sans v√©rif", "termin√© sans"],
    "incomplete": ["manquant", "todo", "non impl√©ment√©", "incomplet", "oubli√©"],
    "contradiction": ["contradiction", "d√©saccord", "conflit"],
    "guardrail_miss": ["supprim√© sans", "√©cras√©", "overwrite", "destroy"],
    "expertise_gap": ["correction", "en fait", "incorrect", "tromp√©"],
}


# ‚îÄ‚îÄ Data classes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@dataclass
class DimensionScore:
    """Score d'une dimension d'anti-fragilit√©."""
    name: str
    score: float           # 0.0 - 1.0
    weight: float
    weighted: float        # score * weight
    evidence_count: int    # nombre de signaux analys√©s
    details: str           # explication textuelle
    recommendations: list[str] = field(default_factory=list)


@dataclass
class AntifragileResult:
    """R√©sultat complet du scoring."""
    timestamp: str
    global_score: float    # 0-100
    level: str             # FRAGILE | ROBUST | ANTIFRAGILE
    dimensions: list[DimensionScore]
    total_evidence: int
    summary: str
    since: Optional[str] = None


# ‚îÄ‚îÄ Collecte des donn√©es ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _count_entries(path: Path, since: Optional[str] = None) -> list[tuple[str, str]]:
    """Parse un markdown et retourne (date, text) pour les entr√©es list√©es."""
    if not path.exists():
        return []
    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return []

    entries = []
    date_pattern = re.compile(r'\[(\d{4}-\d{2}-\d{2})')
    for line in content.splitlines():
        line = line.strip()
        if not line or line.startswith("#"):
            continue
        if line.startswith("- ") or line.startswith("* ") or line.startswith("### ["):
            match = date_pattern.search(line)
            entry_date = match.group(1) if match else ""
            if since and entry_date and entry_date < since:
                continue
            entries.append((entry_date, line))
    return entries


def _count_failure_sections(path: Path, since: Optional[str] = None) -> dict:
    """Compte les sections dans le Failure Museum par cat√©gorie et s√©v√©rit√©."""
    if not path.exists():
        return {"total": 0, "critical": 0, "important": 0, "micro": 0,
                "with_rule": 0, "with_lesson": 0, "categories": {}}

    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return {"total": 0, "critical": 0, "important": 0, "micro": 0,
                "with_rule": 0, "with_lesson": 0, "categories": {}}

    date_pattern = re.compile(r'\[(\d{4}-\d{2}-\d{2})\]')
    result = {"total": 0, "critical": 0, "important": 0, "micro": 0,
              "with_rule": 0, "with_lesson": 0, "categories": {}}

    current_severity = ""
    in_entry = False
    has_rule = False
    has_lesson = False
    entry_date = ""

    for line in content.splitlines():
        # D√©tecter la section s√©v√©rit√©
        if "Top Erreurs Critiques" in line or "üî¥" in line:
            current_severity = "critical"
        elif "Erreurs Importantes" in line or "üü°" in line:
            current_severity = "important"
        elif "Micro-Erreurs" in line or "üü¢" in line:
            current_severity = "micro"

        # D√©tecter une entr√©e
        if line.startswith("### ["):
            if in_entry:
                # Finaliser l'entr√©e pr√©c√©dente
                if has_rule:
                    result["with_rule"] += 1
                if has_lesson:
                    result["with_lesson"] += 1

            match = date_pattern.search(line)
            entry_date = match.group(1) if match else ""
            if since and entry_date and entry_date < since:
                in_entry = False
                continue

            in_entry = True
            has_rule = False
            has_lesson = False
            result["total"] += 1
            if current_severity:
                result[current_severity] = result.get(current_severity, 0) + 1

            # Cat√©goriser
            for cat in FAILURE_CATEGORIES:
                if cat in line:
                    result["categories"][cat] = result["categories"].get(cat, 0) + 1

        if in_entry:
            line_lower = line.lower()
            if "r√®gle instaur√©e" in line_lower or "rule" in line_lower:
                has_rule = True
            if "le√ßon" in line_lower or "lesson" in line_lower:
                has_lesson = True

    # Finaliser la derni√®re entr√©e
    if in_entry:
        if has_rule:
            result["with_rule"] += 1
        if has_lesson:
            result["with_lesson"] += 1

    return result


def _count_contradictions(path: Path) -> dict:
    """Compte les contradictions par statut."""
    if not path.exists():
        return {"total": 0, "active": 0, "resolved": 0}

    try:
        content = path.read_text(encoding="utf-8")
    except OSError:
        return {"total": 0, "active": 0, "resolved": 0}

    result = {"total": 0, "active": 0, "resolved": 0}
    for line in content.splitlines():
        if "|" in line and not line.startswith("|--"):
            result["total"] += 1
            if "‚è≥" in line or "‚ö†Ô∏è" in line:
                result["active"] += 1
            elif "‚úÖ" in line or "resolved" in line.lower():
                result["resolved"] += 1
    return result


def _count_sil_signals(memory_dir: Path, since: Optional[str] = None) -> dict:
    """Compte les signaux SIL dans les sources m√©moire."""
    signals = {cat: 0 for cat in SIL_MARKERS}

    decisions_path = memory_dir / "decisions-log.md"
    learnings_dir = memory_dir / "agent-learnings"

    # Scan decisions-log
    if decisions_path.exists():
        entries = _count_entries(decisions_path, since)
        for _, text in entries:
            text_lower = text.lower()
            for cat, markers in SIL_MARKERS.items():
                if any(m in text_lower for m in markers):
                    signals[cat] += 1

    # Scan learnings
    if learnings_dir.exists():
        for f in learnings_dir.glob("*.md"):
            entries = _count_entries(f, since)
            for _, text in entries:
                text_lower = text.lower()
                for cat, markers in SIL_MARKERS.items():
                    if any(m in text_lower for m in markers):
                        signals[cat] += 1

    return signals


def _count_learnings(memory_dir: Path, since: Optional[str] = None) -> dict:
    """Compte les entr√©es de learnings par agent."""
    learnings_dir = memory_dir / "agent-learnings"
    result = {"total": 0, "agents": {}, "per_agent": []}

    if not learnings_dir.exists():
        return result

    for f in sorted(learnings_dir.glob("*.md")):
        entries = _count_entries(f, since)
        count = len(entries)
        if count > 0:
            agent = f.stem
            result["agents"][agent] = count
            result["per_agent"].append((agent, count))
            result["total"] += count

    return result


def _count_decisions(memory_dir: Path, since: Optional[str] = None) -> dict:
    """Compte les d√©cisions et les reversals."""
    decisions_path = memory_dir / "decisions-log.md"
    result = {"total": 0, "reversals": 0}

    if not decisions_path.exists():
        return result

    entries = _count_entries(decisions_path, since)
    result["total"] = len(entries)

    reversal_markers = ["annul√©", "revert√©", "invers√©", "cancel", "revert",
                        "rollback", "en fait non", "revenir sur", "abandonn√©"]
    for _, text in entries:
        if any(m in text.lower() for m in reversal_markers):
            result["reversals"] += 1

    return result


# ‚îÄ‚îÄ Calcul des dimensions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def score_recovery(failures: dict) -> DimensionScore:
    """Taux de r√©cup√©ration : failures ‚Üí le√ßons ‚Üí r√®gles instaur√©es."""
    total = failures["total"]
    if total == 0:
        return DimensionScore(
            name="R√©cup√©ration", score=0.5, weight=WEIGHTS["recovery"],
            weighted=0.5 * WEIGHTS["recovery"], evidence_count=0,
            details="Aucune failure enregistr√©e ‚Äî score neutre",
            recommendations=["Commencer √† documenter les √©checs dans failure-museum.md"],
        )

    # Score bas√© sur : le√ßons extraites + r√®gles instaur√©es
    lesson_rate = failures["with_lesson"] / total
    rule_rate = failures["with_rule"] / total

    # Une bonne r√©cup√©ration = r√®gles instaur√©es (poids 0.6) + le√ßons (0.4)
    score = rule_rate * 0.6 + lesson_rate * 0.4

    recs = []
    if rule_rate < 0.5:
        recs.append(f"Seulement {failures['with_rule']}/{total} failures ont "
                     "une r√®gle instaur√©e ‚Äî syst√©matiser les r√®gles post-incident")
    if lesson_rate < 0.7:
        recs.append(f"Seulement {failures['with_lesson']}/{total} failures ont "
                     "une le√ßon ‚Äî documenter chaque incident")

    return DimensionScore(
        name="R√©cup√©ration", score=min(1.0, score), weight=WEIGHTS["recovery"],
        weighted=min(1.0, score) * WEIGHTS["recovery"],
        evidence_count=total,
        details=f"{total} failures, {failures['with_lesson']} le√ßons, "
                f"{failures['with_rule']} r√®gles ({rule_rate:.0%})",
        recommendations=recs,
    )


def score_learning_velocity(learnings: dict) -> DimensionScore:
    """Vitesse d'apprentissage : volume et distribution des learnings."""
    total = learnings["total"]
    agents_count = len(learnings["agents"])

    if total == 0:
        return DimensionScore(
            name="V√©locit√© d'apprentissage", score=0.0,
            weight=WEIGHTS["learning_velocity"],
            weighted=0.0, evidence_count=0,
            details="Aucun learning enregistr√©",
            recommendations=["Les agents doivent commencer √† documenter leurs apprentissages"],
        )

    # Score bas√© sur : volume (plafond 50 pour 1.0) + distribution (plus d'agents = mieux)
    volume_score = min(1.0, total / 50)
    distribution_score = min(1.0, agents_count / 5)
    score = volume_score * 0.6 + distribution_score * 0.4

    recs = []
    if agents_count < 3:
        recs.append(f"Seulement {agents_count} agent(s) √©crivent des learnings ‚Äî "
                     "encourager plus d'agents")
    if total < 10:
        recs.append(f"Seulement {total} learnings ‚Äî objectif minimum 10 pour "
                     "une base d'apprentissage utile")

    return DimensionScore(
        name="V√©locit√© d'apprentissage", score=min(1.0, score),
        weight=WEIGHTS["learning_velocity"],
        weighted=min(1.0, score) * WEIGHTS["learning_velocity"],
        evidence_count=total,
        details=f"{total} learnings de {agents_count} agent(s)",
        recommendations=recs,
    )


def score_contradiction_resolution(contradictions: dict) -> DimensionScore:
    """R√©solution des contradictions : indique la capacit√© √† r√©soudre les tensions."""
    total = contradictions["total"]
    if total == 0:
        return DimensionScore(
            name="R√©solution contradictions", score=0.5,
            weight=WEIGHTS["contradiction_resolution"],
            weighted=0.5 * WEIGHTS["contradiction_resolution"],
            evidence_count=0,
            details="Aucune contradiction enregistr√©e ‚Äî score neutre",
        )

    resolved = contradictions["resolved"]
    active = contradictions["active"]
    resolution_rate = resolved / total if total > 0 else 0

    score = resolution_rate
    recs = []
    if active > 0:
        recs.append(f"{active} contradiction(s) active(s) non r√©solues ‚Äî "
                     "prioriser la r√©solution")
    if resolution_rate < 0.5:
        recs.append("Taux de r√©solution < 50% ‚Äî les tensions s'accumulent")

    return DimensionScore(
        name="R√©solution contradictions", score=min(1.0, score),
        weight=WEIGHTS["contradiction_resolution"],
        weighted=min(1.0, score) * WEIGHTS["contradiction_resolution"],
        evidence_count=total,
        details=f"{resolved}/{total} r√©solues ({resolution_rate:.0%}), "
                f"{active} actives",
        recommendations=recs,
    )


def score_signal_trend(sil_signals: dict) -> DimensionScore:
    """Tendance des signaux SIL : moins = mieux (le syst√®me corrige)."""
    total = sum(sil_signals.values())

    if total == 0:
        return DimensionScore(
            name="Tendance signaux SIL", score=0.7,
            weight=WEIGHTS["signal_trend"],
            weighted=0.7 * WEIGHTS["signal_trend"],
            evidence_count=0,
            details="Aucun signal SIL d√©tect√© ‚Äî bon signe ou projet neuf",
        )

    # Moins de signaux = meilleur score (invers√©)
    # 0 signaux ‚Üí 1.0, 20+ ‚Üí ~0.1
    score = max(0.1, 1.0 - (total / 25))

    # Pond√©ration par gravit√©
    cc_fail = sil_signals.get("cc_fail", 0)
    guardrail = sil_signals.get("guardrail_miss", 0)
    critical_count = cc_fail + guardrail
    if critical_count > 3:
        score *= 0.7  # P√©nalit√© critique

    recs = []
    if cc_fail > 0:
        recs.append(f"{cc_fail} CC_FAIL d√©tect√©(s) ‚Äî renforcer le Completion Contract")
    if guardrail > 0:
        recs.append(f"{guardrail} GUARDRAIL_MISS ‚Äî ajouter des gardes automatiques")
    if sil_signals.get("expertise_gap", 0) > 2:
        recs.append("Expertise gaps r√©currents ‚Äî envisager Agent Forge pour sp√©cialiser")

    details_parts = [f"{k}:{v}" for k, v in sil_signals.items() if v > 0]
    return DimensionScore(
        name="Tendance signaux SIL", score=max(0.0, min(1.0, score)),
        weight=WEIGHTS["signal_trend"],
        weighted=max(0.0, min(1.0, score)) * WEIGHTS["signal_trend"],
        evidence_count=total,
        details=f"{total} signaux ({', '.join(details_parts) or 'aucun'})",
        recommendations=recs,
    )


def score_decision_quality(decisions: dict) -> DimensionScore:
    """Qualit√© des d√©cisions : taux de reversal."""
    total = decisions["total"]
    if total == 0:
        return DimensionScore(
            name="Qualit√© des d√©cisions", score=0.5,
            weight=WEIGHTS["decision_quality"],
            weighted=0.5 * WEIGHTS["decision_quality"],
            evidence_count=0,
            details="Aucune d√©cision enregistr√©e ‚Äî score neutre",
        )

    reversal_rate = decisions["reversals"] / total
    # Peu de reversals = good quality
    score = max(0.1, 1.0 - reversal_rate * 3)

    recs = []
    if reversal_rate > 0.2:
        recs.append(f"{decisions['reversals']}/{total} d√©cisions revers√©es "
                     f"({reversal_rate:.0%}) ‚Äî utiliser le consensus adversarial "
                     "pour les d√©cisions critiques")

    return DimensionScore(
        name="Qualit√© des d√©cisions", score=min(1.0, score),
        weight=WEIGHTS["decision_quality"],
        weighted=min(1.0, score) * WEIGHTS["decision_quality"],
        evidence_count=total,
        details=f"{total} d√©cisions, {decisions['reversals']} reversals "
                f"({reversal_rate:.0%})",
        recommendations=recs,
    )


def score_pattern_recurrence(failures: dict, sil_signals: dict) -> DimensionScore:
    """Non-r√©currence des patterns d'√©chec."""
    # V√©rifier si les m√™mes cat√©gories de failure reviennent
    categories = failures.get("categories", {})
    total_cats = sum(categories.values())

    if total_cats == 0:
        return DimensionScore(
            name="Non-r√©currence patterns", score=0.5,
            weight=WEIGHTS["pattern_recurrence"],
            weighted=0.5 * WEIGHTS["pattern_recurrence"],
            evidence_count=0,
            details="Aucun pattern de failure d√©tect√© ‚Äî score neutre",
        )

    # Diversit√© des cat√©gories (max entropy = mieux que concentration)
    unique_cats = len(categories)
    total_possible = len(FAILURE_CATEGORIES)
    diversity = unique_cats / total_possible if total_possible > 0 else 0

    # Concentration = pire (une seule cat√©gorie domine)
    max_cat_count = max(categories.values()) if categories else 0
    concentration = max_cat_count / total_cats if total_cats > 0 else 0

    # Score : haute diversit√© + basse concentration = anti-fragile
    # Basse diversit√© + haute concentration = fragile (toujours la m√™me erreur)
    score = (1.0 - concentration) * 0.6 + diversity * 0.4

    recs = []
    if concentration > 0.6 and max_cat_count > 2:
        worst_cat = max(categories, key=categories.get)
        recs.append(f"Le pattern '{worst_cat}' domine ({max_cat_count}/{total_cats}) "
                     "‚Äî cr√©er un guardrail sp√©cialis√©")

    return DimensionScore(
        name="Non-r√©currence patterns", score=min(1.0, score),
        weight=WEIGHTS["pattern_recurrence"],
        weighted=min(1.0, score) * WEIGHTS["pattern_recurrence"],
        evidence_count=total_cats,
        details=f"{total_cats} failures, {unique_cats} cat√©gories, "
                f"concentration: {concentration:.0%}",
        recommendations=recs,
    )


# ‚îÄ‚îÄ Orchestration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def compute_antifragile_score(project_root: Path,
                              since: Optional[str] = None) -> AntifragileResult:
    """Calcule le score d'anti-fragilit√© global."""
    memory_dir = project_root / "_bmad" / "_memory"
    timestamp = datetime.now().isoformat()

    # Collecter les donn√©es
    failures = _count_failure_sections(memory_dir / "failure-museum.md", since)
    contradictions = _count_contradictions(memory_dir / "contradiction-log.md")
    sil_signals = _count_sil_signals(memory_dir, since)
    learnings = _count_learnings(memory_dir, since)
    decisions = _count_decisions(memory_dir, since)

    # Scorer chaque dimension
    dimensions = [
        score_recovery(failures),
        score_learning_velocity(learnings),
        score_contradiction_resolution(contradictions),
        score_signal_trend(sil_signals),
        score_decision_quality(decisions),
        score_pattern_recurrence(failures, sil_signals),
    ]

    # Score global (0-100)
    global_score = sum(d.weighted for d in dimensions) * 100
    global_score = max(0, min(100, round(global_score, 1)))

    # Niveau
    if global_score < FRAGILE_THRESHOLD:
        level = "FRAGILE"
    elif global_score < ROBUST_THRESHOLD:
        level = "ROBUST"
    else:
        level = "ANTIFRAGILE"

    total_evidence = sum(d.evidence_count for d in dimensions)

    # R√©sum√©
    if total_evidence == 0:
        summary = ("Projet neuf ou peu actif ‚Äî score neutre. "
                   "Accumulez des donn√©es pour un scoring significatif.")
    elif level == "FRAGILE":
        summary = ("Le syst√®me est FRAGILE ‚Äî les √©checs ne produisent pas "
                   "d'apprentissage syst√©matique. Actions urgentes requises.")
    elif level == "ROBUST":
        summary = ("Le syst√®me est ROBUST ‚Äî il survit aux √©checs mais n'en "
                   "tire pas assez de b√©n√©fices. Potentiel d'am√©lioration.")
    else:
        summary = ("Le syst√®me est ANTI-FRAGILE ‚Äî il s'am√©liore activement "
                   "avec chaque stress. Continuer sur cette trajectoire.")

    return AntifragileResult(
        timestamp=timestamp,
        global_score=global_score,
        level=level,
        dimensions=dimensions,
        total_evidence=total_evidence,
        summary=summary,
        since=since,
    )


# ‚îÄ‚îÄ Persistance ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def save_score(result: AntifragileResult, project_root: Path) -> Path:
    """Sauvegarde le score dans l'historique."""
    output_dir = project_root / "_bmad-output"
    output_dir.mkdir(parents=True, exist_ok=True)
    path = output_dir / HISTORY_FILE

    history = []
    if path.exists():
        try:
            history = json.loads(path.read_text(encoding="utf-8"))
        except (json.JSONDecodeError, OSError):
            pass

    entry = {
        "timestamp": result.timestamp,
        "score": result.global_score,
        "level": result.level,
        "evidence": result.total_evidence,
        "dimensions": {
            d.name: {"score": round(d.score * 100, 1), "evidence": d.evidence_count}
            for d in result.dimensions
        },
    }
    history.append(entry)
    path.write_text(json.dumps(history, indent=2, ensure_ascii=False), encoding="utf-8")
    return path


def load_history(project_root: Path) -> list[dict]:
    """Charge l'historique des scores."""
    path = project_root / "_bmad-output" / HISTORY_FILE
    if not path.exists():
        return []
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return []


# ‚îÄ‚îÄ Rendu ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

LEVEL_ICONS = {"FRAGILE": "üî¥", "ROBUST": "üü°", "ANTIFRAGILE": "üü¢"}
LEVEL_BARS = {"FRAGILE": "‚ñà", "ROBUST": "‚ñì", "ANTIFRAGILE": "‚ñë"}


def render_report(result: AntifragileResult) -> str:
    """G√©n√®re le rapport d'anti-fragilit√© en Markdown."""
    icon = LEVEL_ICONS.get(result.level, "‚ùì")
    lines = [
        f"# {icon} Score Anti-Fragilit√© ‚Äî {result.global_score}/100 ({result.level})",
        "",
        f"> {result.summary}",
        f"> **Date** : {result.timestamp[:19]}",
    ]
    if result.since:
        lines.append(f"> **P√©riode** : depuis {result.since}")
    lines.append(f"> **Signaux analys√©s** : {result.total_evidence}")
    lines.extend(["", "---", ""])

    # Score visuel
    filled = int(result.global_score / 5)
    empty = 20 - filled
    bar = "‚ñà" * filled + "‚ñë" * empty
    lines.append(f"## üìä Score Global : `{bar}` {result.global_score}/100")
    lines.extend(["", "---", ""])

    # D√©tail des dimensions
    lines.append("## üîç Dimensions")
    lines.append("")
    lines.append("| Dimension | Score | Poids | Pond√©r√© | Signaux |")
    lines.append("|-----------|-------|-------|---------|---------|")
    for d in sorted(result.dimensions, key=lambda x: x.weighted, reverse=True):
        d_bar = "‚ñà" * int(d.score * 10) + "‚ñë" * (10 - int(d.score * 10))
        lines.append(
            f"| {d.name} | `{d_bar}` {d.score:.0%} | "
            f"{d.weight:.0%} | {d.weighted:.2f} | {d.evidence_count} |"
        )
    lines.extend(["", "---", ""])

    # D√©tails par dimension
    lines.append("## üìã D√©tails par dimension")
    lines.append("")
    for d in result.dimensions:
        status = "üü¢" if d.score >= 0.6 else "üü°" if d.score >= 0.3 else "üî¥"
        lines.append(f"### {status} {d.name}")
        lines.append(f"**Score** : {d.score:.0%} ‚Äî {d.details}")
        if d.recommendations:
            lines.append("")
            lines.append("**Recommandations** :")
            for rec in d.recommendations:
                lines.append(f"- {rec}")
        lines.append("")

    # Recommandations globales
    all_recs = []
    for d in result.dimensions:
        all_recs.extend(d.recommendations)

    if all_recs:
        lines.extend(["---", "", "## üéØ Plan d'action", ""])
        for i, rec in enumerate(all_recs, 1):
            lines.append(f"{i}. {rec}")
        lines.append("")

    return "\n".join(lines)


def render_trend(history: list[dict]) -> str:
    """G√©n√®re un rapport de tendance."""
    if not history:
        return "Aucun historique disponible. Lancez `bmad-init.sh antifragile` pour commencer."

    lines = [
        "## üìà Tendance Anti-Fragilit√©",
        "",
        "| # | Date | Score | Niveau | Signaux |",
        "|---|------|-------|--------|---------|",
    ]
    for i, entry in enumerate(reversed(history), 1):
        ts = entry.get("timestamp", "?")[:10]
        score = entry.get("score", 0)
        level = entry.get("level", "?")
        icon = LEVEL_ICONS.get(level, "‚ùì")
        evidence = entry.get("evidence", 0)
        lines.append(f"| {i} | {ts} | {score}/100 | {icon} {level} | {evidence} |")

    # Tendance
    if len(history) >= 2:
        scores = [h.get("score", 0) for h in history]
        last = scores[-1]
        prev = scores[-2]
        delta = last - prev
        trend = "üìà +" if delta > 0 else "üìâ " if delta < 0 else "‚û°Ô∏è "
        lines.extend(["", f"**Tendance** : {trend}{delta:+.1f} points depuis le dernier run"])

    if len(history) >= 3:
        scores = [h.get("score", 0) for h in history]
        avg = sum(scores) / len(scores)
        lines.append(f"**Moyenne** : {avg:.1f}/100 sur {len(scores)} runs")

    lines.append("")
    return "\n".join(lines)


# ‚îÄ‚îÄ CLI ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main():
    parser = argparse.ArgumentParser(
        description="BMAD Anti-Fragile Score ‚Äî mesure la r√©silience adaptative du syst√®me",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument("--project-root", default=".", help="Racine du projet BMAD")
    parser.add_argument("--since", default=None, help="Date d√©but (YYYY-MM-DD)")
    parser.add_argument("--detail", action="store_true", help="Rapport d√©taill√©")
    parser.add_argument("--trend", action="store_true", help="Tendance historique")
    parser.add_argument("--json", action="store_true", help="Sortie JSON")
    parser.add_argument("--dry-run", action="store_true", help="Ne pas sauvegarder")

    args = parser.parse_args()
    project_root = Path(args.project_root).resolve()

    # Mode tendance
    if args.trend:
        history = load_history(project_root)
        print(render_trend(history))
        return

    # Calcul du score
    result = compute_antifragile_score(project_root, args.since)

    # Sortie JSON
    if args.json:
        data = {
            "score": result.global_score,
            "level": result.level,
            "evidence": result.total_evidence,
            "summary": result.summary,
            "dimensions": {
                d.name: {
                    "score": round(d.score * 100, 1),
                    "weight": d.weight,
                    "evidence": d.evidence_count,
                    "recommendations": d.recommendations,
                }
                for d in result.dimensions
            },
        }
        print(json.dumps(data, indent=2, ensure_ascii=False))
    elif args.detail:
        print(render_report(result))
    else:
        # Sortie compacte
        icon = LEVEL_ICONS.get(result.level, "‚ùì")
        filled = int(result.global_score / 5)
        bar = "‚ñà" * filled + "‚ñë" * (20 - filled)
        print(f"{icon} Anti-Fragile Score : {bar} {result.global_score}/100 ({result.level})")
        print(f"   {result.summary}")
        print()
        for d in sorted(result.dimensions, key=lambda x: x.score):
            d_icon = "üü¢" if d.score >= 0.6 else "üü°" if d.score >= 0.3 else "üî¥"
            print(f"   {d_icon} {d.name}: {d.score:.0%} ({d.evidence_count} signaux)")
        # Recommandations top 3
        all_recs = [r for d in result.dimensions for r in d.recommendations]
        if all_recs:
            print()
            print("   üéØ Actions prioritaires :")
            for rec in all_recs[:3]:
                print(f"      ‚Üí {rec}")

    # Sauvegarder
    if not args.dry_run:
        save_score(result, project_root)
        icon = LEVEL_ICONS.get(result.level, "‚ùì")
        print(f"\n{icon} Score enregistr√© dans {HISTORY_FILE}")


if __name__ == "__main__":
    main()
